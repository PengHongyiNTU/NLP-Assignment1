{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE7455 Assignment 1\n",
    "Peng Hongyi (G2105029E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the provided code at first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: torch.Size([2088628]), Val: torch.Size([217646]), Test: torch.Size([245569])\n"
     ]
    }
   ],
   "source": [
    "data_dir = './data/wikitext-2'\n",
    "corpus = data.Corpus(data_dir)\n",
    "print(f'Train: {corpus.train.shape}, Val: {corpus.valid.shape}, Test: {corpus.test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, bsz):\n",
    "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "EVAL_BATCH_SIZE = 10\n",
    "train_data = batchify(corpus.train, BATCH_SIZE)\n",
    "val_data = batchify(corpus.valid, EVAL_BATCH_SIZE)\n",
    "test_data = batchify(corpus.test, EVAL_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOKENS = len(corpus.dictionary)\n",
    "import model\n",
    "MODEL = \"LSTM\"\n",
    "EMSIZE = 200\n",
    "N_HID = 200\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.2\n",
    "TIED = \"store_true\"\n",
    "LR = 20\n",
    "CLIP_TH = 0.25\n",
    "model = model.RNNModel(MODEL, N_TOKENS, EMSIZE, N_HID, N_LAYERS, DROPOUT, TIED).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "BPTT = 35\n",
    "def get_batch(source, i):\n",
    "    seq_len = min(BPTT, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 |   200/ 2983 batches | lr 20.00 | ms/batch 14.17 | loss  5.85 | ppl   346.21\n",
      "| epoch   0 |   400/ 2983 batches | lr 20.00 | ms/batch 14.28 | loss  5.73 | ppl   308.45\n",
      "| epoch   0 |   600/ 2983 batches | lr 20.00 | ms/batch 14.51 | loss  5.54 | ppl   255.88\n",
      "| epoch   0 |   800/ 2983 batches | lr 20.00 | ms/batch 14.33 | loss  5.49 | ppl   243.37\n",
      "| epoch   0 |  1000/ 2983 batches | lr 20.00 | ms/batch 14.34 | loss  5.45 | ppl   231.66\n",
      "| epoch   0 |  1200/ 2983 batches | lr 20.00 | ms/batch 14.08 | loss  5.43 | ppl   228.43\n",
      "| epoch   0 |  1400/ 2983 batches | lr 20.00 | ms/batch 14.19 | loss  5.47 | ppl   236.80\n",
      "| epoch   0 |  1600/ 2983 batches | lr 20.00 | ms/batch 14.09 | loss  5.62 | ppl   274.80\n",
      "| epoch   0 |  1800/ 2983 batches | lr 20.00 | ms/batch 14.03 | loss  5.48 | ppl   238.77\n",
      "| epoch   0 |  2000/ 2983 batches | lr 20.00 | ms/batch 14.17 | loss  5.47 | ppl   238.45\n",
      "| epoch   0 |  2200/ 2983 batches | lr 20.00 | ms/batch 14.16 | loss  5.38 | ppl   217.58\n",
      "| epoch   0 |  2400/ 2983 batches | lr 20.00 | ms/batch 14.26 | loss  5.42 | ppl   225.39\n",
      "| epoch   0 |  2600/ 2983 batches | lr 20.00 | ms/batch 14.38 | loss  5.41 | ppl   224.13\n",
      "| epoch   0 |  2800/ 2983 batches | lr 20.00 | ms/batch 14.32 | loss  5.32 | ppl   204.65\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "import time\n",
    "import math\n",
    "criterion = nn.NLLLoss()\n",
    "model.train()\n",
    "total_loss = 0\n",
    "start_time = time.time()\n",
    "hidden = model.init_hidden(BATCH_SIZE)\n",
    "for epoch in range(1):\n",
    "    for batch, i in enumerate(range(0, train_data.size(0)-1, BPTT)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        model.zero_grad()\n",
    "        hidden = repackage_hidden(hidden)\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = criterion(output, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), CLIP_TH)\n",
    "        for p in model.parameters():\n",
    "            p.data.add_(p.grad, alpha=-LR)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch % 200 == 0 and batch > 0:\n",
    "            cur_loss = total_loss / 200\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                epoch, batch, len(train_data) // BPTT, LR,\n",
    "                elapsed * 1000 / 200, cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write my own FNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class FNNModel(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1579d4a348c2ef16482c05d3cfac916f73c8945ddf1938a1e045b3bdea82eece"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('VFL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
